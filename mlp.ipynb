{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 11509) (10000, 2)\n"
     ]
    }
   ],
   "source": [
    "data_x = pickle.load(open(\"data_x.pkl\",\"rb\")).toarray()\n",
    "data_y = pickle.load(open(\"data_y.pkl\",\"rb\")).values\n",
    "data_y = keras.utils.to_categorical(data_y)\n",
    "print(data_x.shape,data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kadel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_x,test_x,train_y,test_y = train_test_split(data_x,data_y,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(600,activation=\"relu\"))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(300,activation=\"relu\"))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(20,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(2,activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"sgd\",loss=\"categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.6933 - acc: 0.4964 - val_loss: 0.6930 - val_acc: 0.5130\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.6929 - acc: 0.5110 - val_loss: 0.6928 - val_acc: 0.5025\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.6926 - acc: 0.5186 - val_loss: 0.6925 - val_acc: 0.5075\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.6922 - acc: 0.5385 - val_loss: 0.6921 - val_acc: 0.5270\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.6917 - acc: 0.5369 - val_loss: 0.6916 - val_acc: 0.5775\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.6909 - acc: 0.5736 - val_loss: 0.6910 - val_acc: 0.5345\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.6902 - acc: 0.5658 - val_loss: 0.6903 - val_acc: 0.6165\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.6892 - acc: 0.6100 - val_loss: 0.6896 - val_acc: 0.5295\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.6880 - acc: 0.6026 - val_loss: 0.6885 - val_acc: 0.5475\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.6866 - acc: 0.5970 - val_loss: 0.6870 - val_acc: 0.6355\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.6847 - acc: 0.6262 - val_loss: 0.6858 - val_acc: 0.5730\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.6829 - acc: 0.6416 - val_loss: 0.6836 - val_acc: 0.6165\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.6802 - acc: 0.6475 - val_loss: 0.6811 - val_acc: 0.6465\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.6766 - acc: 0.6625 - val_loss: 0.6783 - val_acc: 0.6000\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 20s 2ms/step - loss: 0.6726 - acc: 0.6680 - val_loss: 0.6738 - val_acc: 0.6610\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 20s 2ms/step - loss: 0.6672 - acc: 0.6623 - val_loss: 0.6686 - val_acc: 0.6740\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 20s 2ms/step - loss: 0.6611 - acc: 0.6824 - val_loss: 0.6627 - val_acc: 0.6505\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.6510 - acc: 0.6973 - val_loss: 0.6546 - val_acc: 0.6550\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.6409 - acc: 0.6999 - val_loss: 0.6441 - val_acc: 0.6740\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.6267 - acc: 0.7156 - val_loss: 0.6307 - val_acc: 0.6850\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 20s 2ms/step - loss: 0.6098 - acc: 0.7200 - val_loss: 0.6181 - val_acc: 0.6820\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 20s 2ms/step - loss: 0.5911 - acc: 0.7239 - val_loss: 0.6032 - val_acc: 0.6825\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.5697 - acc: 0.7389 - val_loss: 0.5877 - val_acc: 0.6980\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.5480 - acc: 0.7512 - val_loss: 0.5764 - val_acc: 0.6950\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.5294 - acc: 0.7575 - val_loss: 0.5807 - val_acc: 0.6790\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.5132 - acc: 0.7614 - val_loss: 0.5944 - val_acc: 0.6725\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 20s 2ms/step - loss: 0.4941 - acc: 0.7784 - val_loss: 0.5585 - val_acc: 0.7035\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 20s 2ms/step - loss: 0.4789 - acc: 0.7827 - val_loss: 0.5562 - val_acc: 0.7150\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.4604 - acc: 0.7956 - val_loss: 0.5593 - val_acc: 0.7010\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.4446 - acc: 0.8098 - val_loss: 0.5630 - val_acc: 0.7040\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.4284 - acc: 0.8139 - val_loss: 0.5700 - val_acc: 0.7045\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 20s 2ms/step - loss: 0.4180 - acc: 0.8206 - val_loss: 0.5648 - val_acc: 0.7085\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 20s 2ms/step - loss: 0.4006 - acc: 0.8281 - val_loss: 0.5879 - val_acc: 0.6955\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 20s 2ms/step - loss: 0.3842 - acc: 0.8426 - val_loss: 0.5829 - val_acc: 0.7065\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.3716 - acc: 0.8450 - val_loss: 0.5831 - val_acc: 0.7095\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.3575 - acc: 0.8530 - val_loss: 0.6191 - val_acc: 0.6910\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.3434 - acc: 0.8670 - val_loss: 0.6674 - val_acc: 0.6840\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.3295 - acc: 0.8704 - val_loss: 0.6308 - val_acc: 0.6965\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 20s 2ms/step - loss: 0.3208 - acc: 0.8712 - val_loss: 0.6325 - val_acc: 0.6980\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.3031 - acc: 0.8806 - val_loss: 0.6296 - val_acc: 0.7020\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.2998 - acc: 0.8816 - val_loss: 0.6730 - val_acc: 0.6885\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.2866 - acc: 0.8880 - val_loss: 0.6931 - val_acc: 0.6870\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.2569 - acc: 0.9051 - val_loss: 0.6608 - val_acc: 0.7055\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.2506 - acc: 0.9094 - val_loss: 0.7245 - val_acc: 0.6860\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.2618 - acc: 0.8980 - val_loss: 0.7059 - val_acc: 0.6940\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.2348 - acc: 0.9126 - val_loss: 0.6814 - val_acc: 0.7005\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.2378 - acc: 0.9091 - val_loss: 0.7067 - val_acc: 0.7050\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.2192 - acc: 0.9200 - val_loss: 0.7072 - val_acc: 0.7020\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.2318 - acc: 0.9084 - val_loss: 0.6897 - val_acc: 0.7010\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.1861 - acc: 0.9360 - val_loss: 0.7300 - val_acc: 0.7005\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.1748 - acc: 0.9383 - val_loss: 0.8057 - val_acc: 0.6840\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.1615 - acc: 0.9460 - val_loss: 0.7397 - val_acc: 0.7005\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.1775 - acc: 0.9387 - val_loss: 0.8330 - val_acc: 0.6870\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.1625 - acc: 0.9419 - val_loss: 0.7524 - val_acc: 0.6960\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.1532 - acc: 0.9484 - val_loss: 0.7904 - val_acc: 0.6905\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.1515 - acc: 0.9501 - val_loss: 0.8518 - val_acc: 0.6920\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.1106 - acc: 0.9699 - val_loss: 0.9237 - val_acc: 0.6890\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.1301 - acc: 0.9620 - val_loss: 0.8798 - val_acc: 0.6950\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.1196 - acc: 0.9652 - val_loss: 0.8344 - val_acc: 0.6955\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.1190 - acc: 0.9620 - val_loss: 0.8209 - val_acc: 0.6980\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.0974 - acc: 0.9739 - val_loss: 0.8695 - val_acc: 0.6995\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.0893 - acc: 0.9762 - val_loss: 0.8293 - val_acc: 0.6955\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.0702 - acc: 0.9830 - val_loss: 0.9034 - val_acc: 0.6960\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.0686 - acc: 0.9824 - val_loss: 0.9324 - val_acc: 0.6940\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 20s 2ms/step - loss: 0.0621 - acc: 0.9858 - val_loss: 0.9680 - val_acc: 0.6920\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0983 - acc: 0.9744 - val_loss: 0.8895 - val_acc: 0.6965\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0873 - acc: 0.9762 - val_loss: 0.9040 - val_acc: 0.6985\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.0517 - acc: 0.9878 - val_loss: 0.9577 - val_acc: 0.6885\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0475 - acc: 0.9885 - val_loss: 1.0292 - val_acc: 0.6920\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.1149 - acc: 0.9666 - val_loss: 0.8081 - val_acc: 0.7005\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0481 - acc: 0.9888 - val_loss: 0.9751 - val_acc: 0.6940\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.1025 - acc: 0.9683 - val_loss: 0.9086 - val_acc: 0.6885\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0597 - acc: 0.9844 - val_loss: 1.0134 - val_acc: 0.6770\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0404 - acc: 0.9899 - val_loss: 1.0293 - val_acc: 0.6875\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0485 - acc: 0.9869 - val_loss: 1.0340 - val_acc: 0.6890\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0331 - acc: 0.9919 - val_loss: 1.0373 - val_acc: 0.6890\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0365 - acc: 0.9910 - val_loss: 1.0547 - val_acc: 0.6915\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0365 - acc: 0.9913 - val_loss: 1.0496 - val_acc: 0.6940\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0650 - acc: 0.9832 - val_loss: 1.1264 - val_acc: 0.6845\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0328 - acc: 0.9919 - val_loss: 1.0419 - val_acc: 0.6950\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0332 - acc: 0.9896 - val_loss: 1.0975 - val_acc: 0.6905\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0289 - acc: 0.9928 - val_loss: 1.0936 - val_acc: 0.6920\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0289 - acc: 0.9920 - val_loss: 1.1128 - val_acc: 0.6885\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0322 - acc: 0.9901 - val_loss: 1.0678 - val_acc: 0.6910\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0461 - acc: 0.9879 - val_loss: 1.1495 - val_acc: 0.6780\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0287 - acc: 0.9915 - val_loss: 1.1411 - val_acc: 0.6910\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 20s 2ms/step - loss: 0.0642 - acc: 0.9846 - val_loss: 1.0421 - val_acc: 0.6900\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0286 - acc: 0.9921 - val_loss: 1.1039 - val_acc: 0.6915\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0259 - acc: 0.9923 - val_loss: 1.1121 - val_acc: 0.6955\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0270 - acc: 0.9913 - val_loss: 1.1376 - val_acc: 0.6920\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0261 - acc: 0.9920 - val_loss: 1.1842 - val_acc: 0.6805\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0279 - acc: 0.9923 - val_loss: 1.1733 - val_acc: 0.6930\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0295 - acc: 0.9906 - val_loss: 1.1913 - val_acc: 0.6890\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0379 - acc: 0.9886 - val_loss: 1.1065 - val_acc: 0.6900\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0249 - acc: 0.9926 - val_loss: 1.1889 - val_acc: 0.6875\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0246 - acc: 0.9924 - val_loss: 1.1740 - val_acc: 0.6810\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0221 - acc: 0.9941 - val_loss: 1.1689 - val_acc: 0.6925\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0230 - acc: 0.9932 - val_loss: 1.1810 - val_acc: 0.6860\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0241 - acc: 0.9932 - val_loss: 1.1860 - val_acc: 0.6850\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.0226 - acc: 0.9929 - val_loss: 1.2731 - val_acc: 0.6865\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 600)               6906000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               180300    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                6020      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 7,092,362\n",
      "Trainable params: 7,092,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x,train_y,epochs=100,validation_data=(test_x,test_y))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 462us/step\n",
      "[1.2731405248641967, 0.6865]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.1650912e-01, 4.8349088e-01],\n",
       "       [4.3301347e-01, 5.6698650e-01],\n",
       "       [9.6265366e-04, 9.9903738e-01],\n",
       "       [4.3319669e-02, 9.5668030e-01],\n",
       "       [1.0837473e-03, 9.9891627e-01],\n",
       "       [9.3451487e-03, 9.9065489e-01],\n",
       "       [2.0792083e-01, 7.9207915e-01],\n",
       "       [3.3782491e-01, 6.6217512e-01],\n",
       "       [9.9871850e-01, 1.2814830e-03],\n",
       "       [9.6359122e-01, 3.6408808e-02]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.evaluate(test_x,test_y))\n",
    "model.predict(test_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save(\"mlp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nat 1000, acc 0.7987\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "at 2000, acc 0.80\n",
    "at 10000, acc 0.9929, val 0.6865\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
